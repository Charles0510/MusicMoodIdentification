{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load features and annotation data\nfeature_df = pd.read_csv('features_sorted.csv')\nannotation_df_1 = pd.read_csv('annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_1_2000.csv')\nannotation_df_2 = pd.read_csv('annotations/annotations averaged per song/song_level/static_annotations_averaged_songs_2000_2058.csv')\nannotation_df = pd.concat([annotation_df_1, annotation_df_2])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Clean column names\nfeature_df.columns = feature_df.columns.str.strip()\nannotation_df.columns = annotation_df.columns.str.strip()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a binary label for classification using the median valence_mean\nmedian_valence = annotation_df['valence_mean'].median()  # Calculate the median\nannotation_df['valence_label'] = annotation_df['valence_mean'].apply(lambda x: 1 if x >= median_valence else 0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check the label distribution\nprint('Label distribution:\\n', annotation_df['valence_label'].value_counts())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(feature_df.drop(columns=['song_id']),\n                                                    annotation_df['valence_label'], \n                                                    test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Random Forest model\nrf_model = RandomForestClassifier(n_estimators=150, max_depth=3, random_state=42)\nrf_model.fit(X_train_scaled, y_train)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make predictions\ny_train_pred = rf_model.predict(X_train_scaled)\ny_test_pred = rf_model.predict(X_test_scaled)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Evaluate model\ntrain_acc = accuracy_score(y_train, y_train_pred)\ntest_acc = accuracy_score(y_test, y_test_pred)\n\nprint(f'Random Forest - Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}')\nprint(f'Random Forest - Confusion Matrix (Test): \\n{confusion_matrix(y_test, y_test_pred)}')"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}